{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUR notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?\n",
    "We formulate and address this problem of constructing low-rankmatrix approximations that depend on actual data elements. Aswith the SVD, the decomposition we desire (i) should have prov-able worst-case optimality and algorithmic properties; (ii) shouldhave a natural statistical interpretation associated with its con-struction; and (iii) should perform well in practice. Cite: Mahoney, Drineas, 2008\n",
    "\n",
    "- C: Columns of A\n",
    "- R: Rows of A\n",
    "- U: Carfeully constructed matrix that guarantees product is \"close\" to A\n",
    "\n",
    "## Statistical Leverage to Improve Matrix Decompositions\n",
    "Compute an importance score for each column/row of A. Use this to randomly sample a small number of columns/rows from A. Recall that the \"jth\" column of A can be expressed exactly as $$A^j = \\sum_{\\xi = 1}^r (\\sigma_{\\xi}u^{\\xi})v_j^{\\xi}$$ where r = rank(A), $\\nu_j^{\\xi}$ is the jth coordinate of the $\\xi$ th right singular vector. Note: $u, v$ from $U, V$ in SVD. Thus, we can approximate $A^j$ with the top $k$ singular vectors as $$A^j \\approx \\sum_{\\xi = 1}^k (\\sigma_{\\xi}u^{\\xi})v_j^{\\xi}$$ The scoring metric can be computed as $$\\pi_j = \\frac{1}{k} \\sum_{\\xi = 1}^k (v_j^{\\xi})^2$$ for all $j = 1, ..., n$ . This forms a probability distribution over the n columns.\n",
    "\n",
    "ColumnSelect Algorithm \n",
    "1. Compute $v^1,...,v^k$ and statistical leverage scores\n",
    "2. Keep the jth column of A with probability $p_j = min{1,c\\pi_j}$, for all j where $c = \\mathcal{O}(klog k/\\epsilon^2)$ . \n",
    "3. Return the matrix C consisting of the selected coluns of A. \n",
    "\n",
    "99% chance the returned columns satisfy $\\| A -P_CA \\|_F \\leq (1 + \\epsilon / 2)\\|A - A_k\\|_F$ where $P_C$ denotes a projection matrix onto the column space of C. Note: $P_CA = CX \\implies X = C^{\\dagger}A$\n",
    "\n",
    "General Algorithm\n",
    "1. Run ColumnSelect on A with inputs A, rank parameter k, and error parameter $\\epsilon$\n",
    "2. Repeate for $A^T$\n",
    "3. Define $U = C^{\\dagger}AR^{\\dagger}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
